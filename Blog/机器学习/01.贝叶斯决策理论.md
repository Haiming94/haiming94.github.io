### 01.贝叶斯决策理论

#### 1.概念

将分类问题转换成决策问题，通过考虑各个类的先验概率和类条件概率进行贝叶斯决策（即后验概率）。考虑先验概率意味着对样本总体的认识，考虑条件概率是对每一类中某个特征出现频率的认识。那么，贝叶斯决策的理论依据就是贝叶斯公式。

#### 2.原理

##### 2.1最小错误率贝叶斯决策

首先来看贝叶斯公式：

$$
P(H|E)=\frac{P(E|H)\cdot P(H)}{P(E)}
$$
其中，总体密度 $P(E)$、先验概率 $P(H)$ 和类条件概率 $P(E|H)$ 计算出后验概率 $P(H|E)$，判断遵从最大厚颜概率。这种仅根据后验概率作决策的方式称为**最小错误率贝叶斯决策**（证明：最小错误率贝叶斯决策的平均错误率是最低）。

【证明】最小错误率贝叶斯决策的平均错误率是最低

假设有一个二分类问题，对于样本 $x$ 的决策错误率满足：
$$
p(e|x)=
\begin{cases}
    P(w_2|x), x \in w_1 \\
	P(w_1|x), x \in w_2
\end{cases}
$$
进一步得到：
$$
p(e|x)=
\begin{cases}
    P(w_2|x)=1-P(w_1|x), x \in w_1 \\
	P(w_1|x)=1-P(w_2|x), x \in w_2
\end{cases}
$$
将决策的错误率看做服从同样分布的样本的理论错误率的期望，则：
$$
P(e)=\int P(e|x)P(x)dx
$$
那么，最小错误率意味着每一个决策都必须遵从最大后验概率，而最小错误率贝叶斯决策的判断方式就是遵从最大后验概率。

【证明完毕】

##### 2.2最小风险贝叶斯决策

另一种方式是考虑决策风险，加入了损失函数，称为**最小风险贝叶斯决策**。

不同于前者的是，最小风险贝叶斯决策考虑了决策风险，即除了关心决策的正确与否，有时我们更关心错误的决策将带来损失。

为实现最小风险贝叶斯决策，在判断函数中加入损失函数：
$$
\lambda _j^{(i)}=\lambda(g(x)=w_i|w_j) (i,j=1,2,...,c)
$$
该式表示将 $j$ 类误判为 $i$ 类的损失， $c$ 为类数。则，由 $\lambda$ 构成一个 $c*c$ 的损失矩阵，即表示决策表。

最小风险贝叶斯决策的判断函数为：
$$
\mathop{argmin}_i R_i(x)=\sum_{j=1}^c \lambda_j^{(i)} P(w_j|x)
$$

#### 3.贝叶斯决策的一般过程

- 估计先验概率：（1）根据实际情况做经验估计；（2）根据样本分布的频率估计频率。

- 计算类条件概率密度：（1）参数估计：类条件概率分布类型已知，参数未知，通过训练样本来估计（最大似然法、Bayes估计）；（2）非参数估计：不判断类条件概率分布类型，直接根据训练样本来估计（Parzen窗、K近邻法）。
- 计算后验概率。
- 若进行最小错误率决策，根据后验概率即可做出决策。
- 若进行最小风险决策，按上式计算。

#### 4.ROC曲线

ROC曲线——receiver operating characteristic curve。以特异度为横轴、敏感度为纵轴绘制，用来评价一种分类方法或者评价多种分类方法的优劣，越贴近左上角，则这种分类方法性能越好。

#### 5.基于贝叶斯决策的文本分类过程

例如文档：Good good study Day day up

(<https://blog.csdn.net/extraman/article/details/41408067>)